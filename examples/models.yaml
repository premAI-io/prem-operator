apiVersion: premlabs.io/v1alpha1
kind: AIModelMap
metadata:
  name: mixtral-8x7b-instruct-v0.1
spec:
  localai:
    - variant: base
      uri: "https://huggingface.co/mudler/LocalAI/resolve/main/examples/configurations/mixtral/mixtral.yaml?download=true"
  vllm:
    - variant: base
      uri: "mistralai/Mixtral-8x7B-Instruct-v0.1"
---
apiVersion: premlabs.io/v1alpha1
kind: AIModelMap
metadata:
  name: tinyllama-1.1b-chat-v0.1
spec:
  localai:
    - variant: q4-k-m
      uri: "https://huggingface.co/TheBloke/TinyLlama-1.1B-Chat-v0.3-GGUF/resolve/main/tinyllama-1.1b-chat-v0.3.Q4_K_M.gguf"
  vllm:
    - variant: awq
      uri: "TheBloke/TinyLlama-1.1B-Chat-v0.1-AWQ"
      dataType: "float16"
---
apiVersion: premlabs.io/v1alpha1
kind: AIDeployment
metadata:
  name: localai-tinyllama
spec:
  engine:
    name: "localai"
  models:
    - modelMapRef: 
        name: tinyllama-1.1b-chat-v0.1
        variant: q4-k-m
    - uri: "phi-2"
  endpoint:
    - domain: "tinyllama.127.0.0.1.nip.io"
