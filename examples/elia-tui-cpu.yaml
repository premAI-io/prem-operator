apiVersion: premlabs.io/v1alpha1
kind: AIDeployment 
metadata:
  name: phi-2-chat
  namespace: default
spec:
  engine:
    name: "localai" 
    options:
      imageTag: v2.15.0-ffmpeg-core
  endpoint:
    - port: 8080 
      domain: "phi-2-chat.127.0.0.1.nip.io"
  models:
    - uri: phi-2-chat
  deployment:
    resources:
      requests:
        cpu: 4
        memory: 8Gi
      limits:
        cpu: 32
        memory: "16Gi"
---          
apiVersion: v1
kind: ConfigMap
metadata:
  name: model-config
data:
  config.toml: |
    default_model="openai/phi-2-chat"
    
    [[models]]
    name="openai/phi-2-chat"
    api_base="http://phi-2-chat:8080/v1"
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: elia
spec:
  replicas: 1
  selector:
    matchLabels:
      app: elia
  template:
    metadata:
      labels:
        app: elia
    spec:
      containers:
      - name: elia
        image: premai/elia:1.7.0
        ports:
        - containerPort: 3000
        stdin: true
        tty: true
        volumeMounts:
        - name: config-volume
          mountPath: /root/.config/elia
          readOnly: true
      volumes:
      - name: config-volume
        configMap:
          name: model-config
          items:
          - key: config.toml
            path: config.toml
