apiVersion: premlabs.io/v1alpha1
kind: AIDeployment 
metadata:
  name: hermes
  namespace: default
spec:
  engine:
    name: "localai" 
    options:
      imageTag: v2.12.4-cublas-cuda12-ffmpeg
  endpoint:
    - port: 8080 
  models:
    - uri: hermes-2-pro-mistral
  deployment:
    accelerator:
      interface: "CUDA"
      minVersion:
        major: 7
    resources:
      requests:
        cpu: 4
        memory: 16Gi
      limits:
        cpu: 64
        memory: "128Gi"
---          
apiVersion: apps/v1
kind: Deployment
metadata:
  name: big-agi-deployment
spec:
  replicas: 1
  selector:
    matchLabels:
      app: big-agi
  template:
    metadata:
      labels:
        app: big-agi
    spec:
      containers:
      - name: big-agi
        image: ghcr.io/enricoros/big-agi
        env:
        - name: LOCALAI_API_HOST
          value: "http://hermes:8080"
        ports:
        - containerPort: 3000
---
apiVersion: v1
kind: Service
metadata:
  name: big-agi-service
spec:
  type: NodePort
  selector:
    app: big-agi
  ports:
  - protocol: TCP
    port: 3000
    targetPort: 3000
